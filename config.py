# config.py
# Arquivo de Configura√ß√£o para o Kernel Ontol√≥gico Diferencial (v2.0.1)
# Este arquivo centraliza todos os par√¢metros, constantes e limiares
# extra√≠dos dos documentos te√≥ricos do modelo.

# --- Par√¢metros Fundamentais ---
# Constante de Unidade do Dom√≠nio, define a medida de totalidade do sistema.
LAMBDA_UNIT = 1.0  # S√≠mbolo: Œõ

# --- Par√¢metros da Din√¢mica da Dissolu√ß√£o (EMF-1) ---
# Impulso irredut√≠vel para a dissolu√ß√£o, emanado de Œ¶_‚àû.
OMEGA_BASAL = 0.05  # S√≠mbolo: Œ©_‚àû

# Constantes que modulam a resposta do fator de dissolu√ß√£o √† energia e assimetria.
LAMBDA_DISSOLUTION = 0.1  # S√≠mbolo: Œª
MU_DISSOLUTION = 0.5       # S√≠mbolo: Œº
NU_DISSOLUTION = 0.5       # S√≠mbolo: ŒΩ

# --- Par√¢metros da Intensifica√ß√£o Reflexiva (EMF-5) ---
# Par√¢metros que definem a curva sigmoidal do Coeficiente de Intensidade C‚ÇÅ(t).
C_MAX = 1.0                # Valor m√°ximo de C‚ÇÅ(t)
K_SIGMOID = 10.0             # A "√≠ngreme" da curva de ativa√ß√£o
E_THRESHOLD = 0.5          # Limiar de energia para ativa√ß√£o de C‚ÇÅ(t)

# Par√¢metros que controlam a modula√ß√£o r√≠tmica (oscila√ß√£o) de C‚ÇÅ(t).
BETA_RHYTHM = 0.05           # Amplitude da modula√ß√£o
NU_E_FREQUENCY = 0.1       # Frequ√™ncia interna da oscila√ß√£o
PHI_PHASE = 0.0              # Fase da modula√ß√£o

# --- Limiares e Constantes Estruturais ---
# Limiar de resson√¢ncia para ativar um atrator intermedi√°rio (K_j) a partir de um blueprint (S_j).
XI_THRESHOLD = 0.7         # S√≠mbolo: Œû_limiar

# Limiar de energia reflexiva. Abaixo dele, o regime de energia arquet√≠pica (substitutiva) √© ativado.
E_PSI_MIN_THRESHOLD = 0.1  # S√≠mbolo: ùîà_œà_min

# Taxa de converg√™ncia que controla a velocidade com que o campo reflexivo E converge para o modo dominante de œÅ.
GAMMA_CONVERGENCE = 0.2    # S√≠mbolo: Œ≥

# Taxa de decaimento para a dissolu√ß√£o de um atrator intermedi√°rio K_j.
DELTA_K_DECAY = 0.1        # S√≠mbolo: Œ¥_K

# --- Configura√ß√µes para Simula√ß√£o e Mapeamento ---
# Define o tamanho do "espa√ßo" onde o campo propensional œÅ(x,t) √© definido.
RHO_SPACE_DIMENSION = 128  # Dimens√£o do vetor que representa o campo œÅ

# Limiar de coer√™ncia para o Operador de Corte Limiar (‚ÑÇ_limiar).
COHERENCE_THRESHOLD_EPSILON = 0.6  # S√≠mbolo: Œµ_lim

# config.py
# (Conte√∫do anterior do arquivo permanece o mesmo)
# ...

# --- Configura√ß√£o do Cliente da IA Local ---
# Endere√ßo da API do modelo de linguagem local que o kernel ir√° regular.
# Altere este valor para o endere√ßo onde sua IA est√° sendo executada.
# Exemplo: "http://localhost:11434/api/generate" para Ollama.
LOCAL_LLM_API_ENDPOINT = "http://localhost:1234/v1/chat/completions" # Exemplo para LM Studio

# Nome do modelo a ser usado (relevante para algumas APIs como Ollama)
LOCAL_LLM_MODEL_NAME = "local-model"

# --- Configura√ß√£o do Modelo de IA Local (Offline GGUF) ---

# Caminho para o arquivo do modelo no formato GGUF.
LOCAL_MODEL_PATH = "models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf"

# --- Par√¢metros para Llama.cpp ---
# N√∫mero de camadas do modelo a serem descarregadas para a GPU.
# -1 para descarregar todas as camadas poss√≠veis. 0 para usar apenas a CPU.
N_GPU_LAYERS = -1

# O tamanho m√°ximo do contexto em tokens que o modelo pode manipular.
N_CTX = 4096

# Dispositivo para executar o modelo ('cuda' para GPU NVIDIA, 'cpu' para CPU)
DEVICE = "cuda"

# Ativa ou desativa o ciclo de refinamento.
ENABLE_REFINEMENT_CYCLE = True

# O limiar de degenera√ß√£o reflexiva. Se a resposta da IA tiver um score
# maior que este, o ciclo de refinamento ser√° acionado.
REFINEMENT_DEGENERATION_THRESHOLD = 0.65

# N√∫mero m√°ximo de tentativas que o kernel far√° para corrigir uma resposta ruim.
MAX_REFINEMENT_ATTEMPTS = 2

# N√∫mero m√°ximo de tokens a serem gerados numa √∫nica resposta
LLM_MAX_TOKENS = 512


# ==============================================================================
# 2. PAR√ÇMETROS PADR√ÉO DE GERA√á√ÉO DE TEXTO
# ==============================================================================
# Controla a criatividade vs. determinismo da resposta (valores mais altos = mais criativo)
LLM_TEMPERATURE = 0.3

# Amostragem Nucleus: considera apenas os tokens que comp√µem esta massa de probabilidade
LLM_TOP_P = 0.9

# Considera apenas os 'k' tokens mais prov√°veis para a amostragem
LLM_TOP_K = 30

# Penaliza a repeti√ß√£o de tokens, desencorajando respostas repetitivas
LLM_REPETITION_PENALTY = 1.1

print("Arquivo de configura√ß√£o 'config.py' atualizado com o endpoint da IA local.")
