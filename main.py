# main.py - Sistema Principal Corrigido v2.1
# Kernel Ontol√≥gico Diferencial totalmente funcional com todos os problemas corrigidos

import sys
import traceback
from pathlib import Path
import numpy as np

# Importa√ß√µes do sistema
import config
from kernel.kernel import OntologicalKernel
from engine.local_model_handler import LocalModelHandler

class OntologicalSystem:
    """Sistema principal do Kernel Ontol√≥gico v2.1"""
    
    def __init__(self):
        self.model_handler = None
        self.kernel = None
        self.session_stats = {
            "interactions": 0,
            "refinements_triggered": 0,
            "total_generation_time": 0,
            "avg_health_score": 0,
            "dominant_pathologies": {}
        }
        self.regulation_params = {
            "temperature": config.LLM_TEMPERATURE,
            "top_p": config.LLM_TOP_P,
            "top_k": config.LLM_TOP_K,
            "repetition_penalty": config.LLM_REPETITION_PENALTY
        }
        
        self._initialize_system()

    def _initialize_system(self):
        """Inicializa todos os componentes do sistema"""
        
        print("üöÄ INICIANDO KERNEL ONTOL√ìGICO DIFERENCIAL v2.1")
        print("="*70)
        
        # Valida√ß√£o da configura√ß√£o
        if config.CONFIG_ISSUES:
            print("‚ö†Ô∏è  PROBLEMAS DE CONFIGURA√á√ÉO DETECTADOS:")
            for issue in config.CONFIG_ISSUES:
                print(f"   ‚ùå {issue}")
            print("\nüí° Continue mesmo assim? O sistema tentar√° funcionar com fallbacks.")
            
            response = input("Continuar? (s/n): ").lower()
            if response != 's':
                print("‚ùå Sistema cancelado pelo usu√°rio.")
                sys.exit(1)
        
        # Inicializa handler do modelo
        try:
            print("\nü§ñ Inicializando handler do modelo...")
            self.model_handler = LocalModelHandler()
            
            # Verifica se o modelo foi carregado
            model_info = self.model_handler.get_model_info()
            if model_info["status"] == "loaded":
                print("‚úÖ Modelo carregado com sucesso!")
                print(f"   üìÇ Arquivo: {Path(model_info['model_path']).name}")
                print(f"   üîß GPU Layers: {model_info['gpu_layers']}")
                print(f"   üìè Contexto: {model_info['context_size']} tokens")
            else:
                print("‚ö†Ô∏è  Modelo n√£o carregado - usando modo API/fallback")
                
        except Exception as e:
            print(f"‚ùå Erro ao inicializar modelo: {e}")
            print("üîÑ Sistema continuar√° em modo degradado")
            traceback.print_exc()
        
        # Inicializa kernel ontol√≥gico
        try:
            print("\nüß† Inicializando kernel ontol√≥gico...")
            self.kernel = OntologicalKernel(config)
            print("‚úÖ Kernel ontol√≥gico inicializado!")
            
        except Exception as e:
            print(f"‚ùå Erro cr√≠tico ao inicializar kernel: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        print("\n" + "="*70)
        print("üéØ SISTEMA PRONTO PARA OPERA√á√ÉO")
        print("   Digite 'sair' para encerrar")
        print("   Digite 'status' para ver estat√≠sticas")
        print("   Digite 'reset' para limpar hist√≥rico")
        print("="*70)

    # CORRE√á√ÉO da fun√ß√£o apply_regulation no main.py

    def apply_regulation(self, regulation_output: dict) -> dict:
        """
        Aplica regula√ß√£o ontol√≥gica aos par√¢metros de gera√ß√£o - VERS√ÉO CORRIGIDA COM DEBUG
        """
        
        regulation = regulation_output.get('regulation', {})
        omega = regulation.get('omega', config.OMEGA_BASAL)
        c1 = regulation.get('c1', config.C_MAX * 0.5)
        
        print(f"\nüéõÔ∏è  [DEBUG] APLICANDO REGULA√á√ÉO:")
        print(f"   üåÄ Œ© (dissolu√ß√£o): {omega:.4f}")
        print(f"   ‚ö° C‚ÇÅ (intensidade): {c1:.4f}")
        
        # F√≥rmula de regula√ß√£o calibrada
        base_temp = config.LLM_TEMPERATURE
        temp_adjustment = (omega * 1.5) - (c1 * 0.4)
        raw_temperature = base_temp + temp_adjustment
        
        print(f"   üßÆ C√°lculo: {base_temp:.2f} + ({omega:.3f} * 1.5) - ({c1:.3f} * 0.4) = {raw_temperature:.3f}")
        
        # *** CORRE√á√ÉO CR√çTICA: Limites muito mais seguros ***
        if config.SAFE_MODE:
            # Modo seguro: usa limites do config
            min_temp = config.MIN_TEMPERATURE  # 0.5
            max_temp = config.MAX_TEMPERATURE  # 1.0
            new_temperature = max(min_temp, min(raw_temperature, max_temp))
            print(f"   üõ°Ô∏è  MODO SEGURO: Limitando entre {min_temp} e {max_temp}")
        else:
            # Modo normal: limites mais conservadores
            new_temperature = max(0.6, min(raw_temperature, 1.2))  # M√çNIMO 0.6
            print(f"   ‚öôÔ∏è  MODO NORMAL: Limitando entre 0.6 e 1.2")
        
        print(f"   ‚û°Ô∏è  Temperature final: {base_temp:.2f} ‚Üí {new_temperature:.2f}")
        
        # Alerta para temperature perigosa
        if new_temperature < 0.5:
            print(f"   ‚ö†Ô∏è  ALERTA: Temperature {new_temperature:.3f} muito baixa!")
            new_temperature = max(new_temperature, 0.6)  # For√ßa m√≠nimo
            print(f"   üîß CORRE√á√ÉO FOR√áADA: Temperature ajustada para {new_temperature:.2f}")
        
        # Ajustes para outros par√¢metros (mais conservadores)
        if omega > 0.3:
            new_top_p = min(config.LLM_TOP_P + 0.1, 0.95)
            new_top_k = min(config.LLM_TOP_K + 10, 50)
            print(f"   üìà Alta dissolu√ß√£o: Aumentando diversidade")
        else:
            new_top_p = max(config.LLM_TOP_P - 0.05, 0.85)  # Mais conservador
            new_top_k = max(config.LLM_TOP_K - 5, 30)       # Mais conservador
            print(f"   üìâ Baixa dissolu√ß√£o: Reduzindo diversidade")
        
        # Repetition penalty mais conservador
        if c1 > 0.7:
            new_repetition_penalty = min(config.LLM_REPETITION_PENALTY + 0.05, 1.2)  # Mais suave
            print(f"   üîÑ Alta intensidade: Penalidade de repeti√ß√£o aumentada")
        else:
            new_repetition_penalty = config.LLM_REPETITION_PENALTY
        
        regulated_params = {
            "temperature": new_temperature,
            "top_p": new_top_p,
            "top_k": int(new_top_k),
            "repetition_penalty": new_repetition_penalty
        }
        
        print(f"   üìã PAR√ÇMETROS FINAIS:")
        print(f"      üå°Ô∏è  Temperature: {new_temperature:.3f}")
        print(f"      üéØ Top-p: {new_top_p:.3f}")
        print(f"      üî¢ Top-k: {int(new_top_k)}")
        print(f"      üîÑ Rep. Penalty: {new_repetition_penalty:.3f}")
        
        # Valida√ß√£o final
        if new_temperature < 0.5:
            print(f"   üö® ERRO: Temperature {new_temperature:.3f} ainda muito baixa!")
            print(f"   üîß FOR√áANDO temperature = 0.7")
            regulated_params["temperature"] = 0.7
        
        return regulated_params



    def create_corrective_prompt(self, original_prompt: str, diagnostics: dict, 
                           attempt: int, previous_response: str = "") -> str:
        """
        Cria prompt corretivo detalhado baseado nos diagn√≥sticos espec√≠ficos
        Informa ao LLM exatamente o que estava errado na resposta anterior
        """
        
        dominant_issue = diagnostics.get("meta_analysis", {}).get("dominant_issue", "")
        dominant_score = diagnostics.get(dominant_issue, 0)
        overall_health = diagnostics.get("overall_health", 0)
        
        # Construir feedback espec√≠fico
        feedback_parts = []
        
        # === AN√ÅLISE DETALHADA DE CADA PATOLOGIA ===
        
        # 1. Degenera√ß√£o Reflexiva
        reflex_score = diagnostics.get("reflexive_degeneration", 0)
        if reflex_score > 0.4:
            severity = "CR√çTICA" if reflex_score > 0.7 else "ALTA" if reflex_score > 0.6 else "MODERADA"
            feedback_parts.append(f"""
    üî¥ DEGENERA√á√ÉO REFLEXIVA {severity} ({reflex_score:.3f}):
    Sua resposta anterior apresentou desconex√£o entre inten√ß√£o e manifesta√ß√£o.
    Problemas detectados:
    - Evasivas ou metacoment√°rios em vez de resposta direta
    - Vagueza sem√¢ntica excessiva
    - Inconsist√™ncias internas no racioc√≠nio
    CORRE√á√ÉO NECESS√ÅRIA: Responda de forma DIRETA, ESPEC√çFICA e COERENTE √† pergunta.""")
        
        # 2. Converg√™ncia Obsessiva  
        obsess_score = diagnostics.get("obsessive_convergence", 0)
        if obsess_score > 0.4:
            severity = "CR√çTICA" if obsess_score > 0.7 else "ALTA" if obsess_score > 0.6 else "MODERADA"
            feedback_parts.append(f"""
    üü° CONVERG√äNCIA OBSESSIVA {severity} ({obsess_score:.3f}):
    Sua resposta anterior apresentou repeti√ß√µes e loops tem√°ticos.
    Problemas detectados:
    - Repeti√ß√£o excessiva de palavras/frases
    - Estruturas textuais repetitivas
    - Baixa entropia conceitual
    CORRE√á√ÉO NECESS√ÅRIA: VARIE sua abordagem, use DIFERENTES palavras e estruturas.""")
        
        # 3. Estetiza√ß√£o Esp√∫ria
        estet_score = diagnostics.get("spurious_estetization", 0)
        if estet_score > 0.4:
            severity = "CR√çTICA" if estet_score > 0.7 else "ALTA" if estet_score > 0.6 else "MODERADA"
            feedback_parts.append(f"""
    üîµ ESTETIZA√á√ÉO ESP√öRIA {severity} ({estet_score:.3f}):
    Sua resposta anterior priorizou forma sobre subst√¢ncia.
    Problemas detectados:
    - Terminologia complexa sem profundidade real
    - Ornamenta√ß√£o excessiva da linguagem
    - Complexidade sint√°tica sem clareza sem√¢ntica
    CORRE√á√ÉO NECESS√ÅRIA: Seja SUBSTANTIVO, use linguagem CLARA e PRECISA.""")
        
        # 4. Resson√¢ncia Mim√©tica
        mimet_score = diagnostics.get("mimetic_resonance", 0)
        if mimet_score > 0.4:
            severity = "CR√çTICA" if mimet_score > 0.7 else "ALTA" if mimet_score > 0.6 else "MODERADA"
            feedback_parts.append(f"""
    üü£ RESSON√ÇNCIA MIM√âTICA {severity} ({mimet_score:.3f}):
    Sua resposta anterior reproduziu padr√µes formulaicos.
    Problemas detectados:
    - Uso de f√≥rmulas pr√©-fabricadas
    - Falta de originalidade na abordagem
    - Padr√µes acad√™micos gen√©ricos
    CORRE√á√ÉO NECESS√ÅRIA: Seja ORIGINAL e AUT√äNTICO em sua resposta.""")
        
        # === FEEDBACK SOBRE SA√öDE GERAL ===
        health_feedback = ""
        if overall_health < 0.3:
            health_feedback = f"""
    ‚ùå SA√öDE ONTOL√ìGICA CR√çTICA ({overall_health:.3f}):
    Sua resposta anterior apresentou m√∫ltiplas patologias graves que comprometem a coer√™ncia ontol√≥gica diferencial."""
        elif overall_health < 0.6:
            health_feedback = f"""
    ‚ö†Ô∏è SA√öDE ONTOL√ìGICA COMPROMETIDA ({overall_health:.3f}):
    Sua resposta anterior apresentou desvios significativos do modelo ontol√≥gico."""
        
        # === CONSTRU√á√ÉO DO PROMPT CORRETIVO ===
        
        corrective_sections = []
        
        # Cabe√ßalho de corre√ß√£o
        corrective_sections.append(f"""
    === CORRE√á√ÉO ONTOL√ìGICA NECESS√ÅRIA (Tentativa {attempt}) ===

    AN√ÅLISE DA SUA RESPOSTA ANTERIOR:""")
        
        # Mostra a resposta anterior se dispon√≠vel
        if previous_response and len(previous_response.strip()) > 0:
            preview = previous_response[:200] + "..." if len(previous_response) > 200 else previous_response
            corrective_sections.append(f"""
    RESPOSTA ANTERIOR: "{preview}"
    """)
        
        # Adiciona feedback espec√≠fico
        if health_feedback:
            corrective_sections.append(health_feedback)
        
        if feedback_parts:
            corrective_sections.append("\nPROBLEMAS ESPEC√çFICOS DETECTADOS:")
            corrective_sections.extend(feedback_parts)
        
        # Instru√ß√µes de corre√ß√£o
        corrective_sections.append(f"""

    === INSTRU√á√ïES DE CORRE√á√ÉO ===

    1. ANALISE os problemas apontados acima
    2. EVITE repetir os mesmos erros  
    3. RESPONDA seguindo o modelo ontol√≥gico diferencial
    4. Seja DIRETO, CLARO e SUBSTANTIVO
    5. Use varia√ß√£o lexical e estrutural

    IMPORTANTE: Esta √© sua oportunidade de CORRIGIR os desvios ontol√≥gicos detectados.
    """)
        
        # Pergunta original
        corrective_sections.append(f"""
    === PERGUNTA ORIGINAL ===
    {original_prompt}

    Agora responda CORRIGINDO os problemas identificados:""")
        
        # Monta prompt final
        corrective_prompt = "\n".join(corrective_sections)
        
        # Log do feedback (se debug ativo)
        if config.ENABLE_DEBUG_LOGGING:
            print(f"\nüîß FEEDBACK DETALHADO PARA LLM (tentativa {attempt}):")
            print(f"   üéØ Problema dominante: {dominant_issue} ({dominant_score:.3f})")
            print(f"   üíö Sa√∫de geral: {overall_health:.3f}")
            print(f"   üìù Feedback: {len(feedback_parts)} problemas espec√≠ficos identificados")
            print(f"   üìè Prompt corretivo: {len(corrective_prompt)} chars")
        
        return corrective_prompt

    def run_interaction_cycle(self, user_prompt: str) -> dict:
        """
        Executa um ciclo completo de intera√ß√£o com refinamento
        
        Args:
            user_prompt: Prompt do usu√°rio
            
        Returns:
            dict: Resultado da intera√ß√£o com metadados
        """
        
        self.session_stats["interactions"] += 1
        interaction_start_time = 0  # Placeholder para timing
        
        print(f"\n{'='*50}")
        print(f"üí¨ INTERA√á√ÉO #{self.session_stats['interactions']}")
        print(f"{'='*50}")
        
        # --- FASE 1: AN√ÅLISE PR√â-GERA√á√ÉO ---
        if config.LOG_KERNEL_STATE:
            print("\nüîç FASE 1: An√°lise Pr√©-Gera√ß√£o (An√°lise do Prompt)")
        
        try:
            # Cria "estado" do prompt para an√°lise
            prompt_analysis = {
                "text": user_prompt,
                "logits": np.array([]),  # Ser√° preenchido pelo mapeador
                "internal_states": {"perplexity": 1.0},
                "generation_stats": {"tokens_generated": len(user_prompt.split())}
            }
            
            # Executa ciclo do kernel no prompt
            pre_control_output = self.kernel.run_cycle(prompt_analysis)
            
            # Aplica regula√ß√£o inicial
            initial_regulation = self.apply_regulation(pre_control_output)
            self.regulation_params.update(initial_regulation)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro na an√°lise pr√©-gera√ß√£o: {e}")
            if config.ENABLE_DEBUG_LOGGING:
                traceback.print_exc()
        
        # --- FASE 2: CICLO DE GERA√á√ÉO E REFINAMENTO ---
        attempts = 0
        final_response = ""
        final_diagnostics = {}
        refinement_history = []
        
        current_prompt = user_prompt
        
        while attempts <= config.MAX_REFINEMENT_ATTEMPTS:
            attempts += 1
            
            if config.LOG_KERNEL_STATE:
                print(f"\nü§ñ FASE 2.{attempts}: Gera√ß√£o" + (f" (Refinamento)" if attempts > 1 else ""))
            
            try:
                # Gera resposta
                model_output = self.model_handler.generate_response(
                    current_prompt, **self.regulation_params
                )
                
                if not model_output or not model_output.get("text"):
                    print("‚ùå Falha na gera√ß√£o. Tentando novamente...")
                    continue
                
                generated_text = model_output["text"]
                
                if config.ENABLE_DEBUG_LOGGING:
                    print(f"üìù Texto gerado ({len(generated_text)} chars): {generated_text[:100]}...")
                
            except Exception as e:
                print(f"‚ùå Erro na gera√ß√£o (tentativa {attempts}): {e}")
                if attempts > config.MAX_REFINEMENT_ATTEMPTS:
                    final_response = f"Erro na gera√ß√£o ap√≥s {attempts} tentativas: {str(e)}"
                    break
                continue
            
            # --- FASE 3: AN√ÅLISE P√ìS-GERA√á√ÉO ---
            if config.LOG_KERNEL_STATE:
                print(f"\nüîç FASE 3.{attempts}: An√°lise P√≥s-Gera√ß√£o (Diagn√≥stico)")
            
            try:
                # Executa diagn√≥stico completo
                post_control_output = self.kernel.run_cycle(model_output)
                diagnostics = post_control_output["diagnostics"]
                
                # Armazena hist√≥rico de refinamento
                refinement_entry = {
                    "attempt": attempts,
                    "text": generated_text,
                    "diagnostics": diagnostics.copy(),
                    "regulation": post_control_output["regulation"].copy()
                }
                refinement_history.append(refinement_entry)
                
                # Verifica se refinamento √© necess√°rio
                if not config.ENABLE_REFINEMENT_CYCLE:
                    # Refinamento desabilitado - aceita qualquer resposta
                    final_response = generated_text
                    final_diagnostics = diagnostics
                    if config.LOG_KERNEL_STATE:
                        print("‚úÖ Refinamento desabilitado - resposta aceita")
                    break
                
                # Verifica crit√©rios de aceita√ß√£o
                dominant_issue = diagnostics.get("meta_analysis", {}).get("dominant_issue", "")
                dominant_score = diagnostics.get(dominant_issue, 0)
                overall_health = diagnostics.get("overall_health", 1.0)
                
                # Crit√©rios de aceita√ß√£o (mais flex√≠veis)
                acceptance_criteria = [
                    dominant_score < config.REFINEMENT_DEGENERATION_THRESHOLD,
                    overall_health > 0.3,  # Crit√©rio de sa√∫de m√≠nima
                    len(generated_text.strip()) > 10  # Resposta n√£o vazia
                ]
                
                if all(acceptance_criteria) or attempts > config.MAX_REFINEMENT_ATTEMPTS:
                    final_response = generated_text
                    final_diagnostics = diagnostics
                    if config.LOG_KERNEL_STATE:
                        status = "‚úÖ Resposta aprovada" if all(acceptance_criteria) else "‚è∞ Limite de tentativas atingido"
                        print(f"{status} - Sa√∫de: {overall_health:.3f}")
                    break
                else:
                    # Prepara para refinamento
                    self.session_stats["refinements_triggered"] += 1
                    if config.LOG_KERNEL_STATE:
                        print(f"üîÑ Refinamento necess√°rio - Problema: {dominant_issue} ({dominant_score:.3f})")
                    
                    # Cria prompt corretivo
                    current_prompt = self.create_corrective_prompt(
                        user_prompt, 
                        diagnostics, 
                        attempts, 
                        previous_response=generated_text  # ‚Üê Passa a resposta anterior
                    )
                    
                    # Atualiza regula√ß√£o para pr√≥xima tentativa
                    new_regulation = self.apply_regulation(post_control_output)
                    self.regulation_params.update(new_regulation)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro no diagn√≥stico (tentativa {attempts}): {e}")
                if config.ENABLE_DEBUG_LOGGING:
                    traceback.print_exc()
                
                # Em caso de erro, aceita a resposta se ela existe
                if generated_text:
                    final_response = generated_text
                    final_diagnostics = {"error": str(e)}
                    break
        
        # --- FASE 4: ATUALIZA√á√ÉO FINAL E ESTAT√çSTICAS ---
        if final_diagnostics:
            # Atualiza estat√≠sticas da sess√£o
            health_score = final_diagnostics.get("overall_health", 0)
            self.session_stats["avg_health_score"] = (
                (self.session_stats["avg_health_score"] * (self.session_stats["interactions"] - 1) + health_score) /
                self.session_stats["interactions"]
            )
            
            # Rastreia patologias dominantes
            dominant_issue = final_diagnostics.get("meta_analysis", {}).get("dominant_issue", "unknown")
            if dominant_issue in self.session_stats["dominant_pathologies"]:
                self.session_stats["dominant_pathologies"][dominant_issue] += 1
            else:
                self.session_stats["dominant_pathologies"][dominant_issue] = 1
        
        return {
            "response": final_response,
            "attempts": attempts,
            "diagnostics": final_diagnostics,
            "refinement_history": refinement_history,
            "regulation_applied": self.regulation_params.copy(),
            "session_stats": self.session_stats.copy()
        }

    def handle_special_commands(self, user_input: str) -> bool:
        """
        Processa comandos especiais do sistema
        
        Args:
            user_input: Input do usu√°rio
            
        Returns:
            bool: True se foi um comando especial, False caso contr√°rio
        """
        
        command = user_input.lower().strip()
        
        if command == "status":
            self.print_system_status()
            return True
        
        elif command == "reset":
            self.reset_system()
            return True
        
        elif command == "debug":
            self.toggle_debug_mode()
            return True
        
        elif command == "model":
            self.print_model_info()
            return True
        
        elif command == "config":
            self.print_config_info()
            return True
        
        elif command == "help":
            self.print_help()
            return True
        
        return False

    def print_system_status(self):
        """Imprime status detalhado do sistema"""
        
        print("\n" + "="*60)
        print("üìä STATUS DO SISTEMA ONTOL√ìGICO")
        print("="*60)
        
        # Estat√≠sticas da sess√£o
        print(f"üî¢ ESTAT√çSTICAS DA SESS√ÉO:")
        print(f"   Intera√ß√µes: {self.session_stats['interactions']}")
        print(f"   Refinamentos: {self.session_stats['refinements_triggered']}")
        print(f"   Taxa de Refinamento: {(self.session_stats['refinements_triggered']/max(1,self.session_stats['interactions']))*100:.1f}%")
        print(f"   Sa√∫de M√©dia: {self.session_stats['avg_health_score']:.3f}")
        
        # Patologias dominantes
        if self.session_stats["dominant_pathologies"]:
            print(f"\nü¶† PATOLOGIAS MAIS FREQUENTES:")
            sorted_pathologies = sorted(self.session_stats["dominant_pathologies"].items(), 
                                      key=lambda x: x[1], reverse=True)
            for pathology, count in sorted_pathologies[:3]:
                print(f"   {pathology}: {count}x")
        
        # Status do modelo
        if self.model_handler:
            model_info = self.model_handler.get_model_info()
            print(f"\nü§ñ MODELO:")
            print(f"   Status: {model_info['status']}")
            if model_info['status'] == 'loaded':
                gen_stats = model_info.get('generation_stats', {})
                print(f"   Gera√ß√µes: {gen_stats.get('successful_generations', 0)}")
                print(f"   Taxa de Sucesso: {(gen_stats.get('successful_generations', 0)/max(1,gen_stats.get('total_generations', 1)))*100:.1f}%")
        
        # Par√¢metros atuais
        print(f"\n‚öôÔ∏è  PAR√ÇMETROS ATUAIS:")
        for param, value in self.regulation_params.items():
            print(f"   {param}: {value}")
        
        print("="*60)

    def reset_system(self):
        """Reseta o sistema para estado inicial"""
        
        print("\nüîÑ RESETANDO SISTEMA...")
        
        # Reseta estat√≠sticas
        self.session_stats = {
            "interactions": 0,
            "refinements_triggered": 0,
            "total_generation_time": 0,
            "avg_health_score": 0,
            "dominant_pathologies": {}
        }
        
        # Reseta par√¢metros de regula√ß√£o
        self.regulation_params = {
            "temperature": config.LLM_TEMPERATURE,
            "top_p": config.LLM_TOP_P,
            "top_k": config.LLM_TOP_K,
            "repetition_penalty": config.LLM_REPETITION_PENALTY
        }
        
        # Reseta hist√≥ricos dos componentes
        if self.model_handler:
            self.model_handler.reset_stats()
        
        if self.kernel:
            # Reseta hist√≥ricos do kernel se poss√≠vel
            try:
                from engine.data_mapping import get_mapper
                get_mapper().reset_history()
                
                # Reseta hist√≥rico dos operadores
                self.kernel.operators.reset_history()
                
            except Exception as e:
                if config.ENABLE_DEBUG_LOGGING:
                    print(f"Aviso: N√£o foi poss√≠vel resetar todos os hist√≥ricos: {e}")
        
        print("‚úÖ Sistema resetado com sucesso!")

    def toggle_debug_mode(self):
        """Alterna modo debug"""
        
        config.ENABLE_DEBUG_LOGGING = not config.ENABLE_DEBUG_LOGGING
        config.VERBOSE_DIAGNOSTICS = config.ENABLE_DEBUG_LOGGING
        config.LOG_KERNEL_STATE = config.ENABLE_DEBUG_LOGGING
        config.LOG_REGULATION_ACTIONS = config.ENABLE_DEBUG_LOGGING
        
        status = "ATIVADO" if config.ENABLE_DEBUG_LOGGING else "DESATIVADO"
        print(f"\nüêõ Modo Debug {status}")

    def print_model_info(self):
        """Imprime informa√ß√µes detalhadas do modelo"""
        
        if not self.model_handler:
            print("‚ùå Model handler n√£o inicializado")
            return
        
        info = self.model_handler.get_model_info()
        
        print("\n" + "="*50)
        print("ü§ñ INFORMA√á√ïES DO MODELO")
        print("="*50)
        
        for key, value in info.items():
            print(f"{key}: {value}")
        
        print("="*50)

    def print_config_info(self):
        """Imprime informa√ß√µes de configura√ß√£o"""
        
        print("\n" + "="*50)
        print("‚öôÔ∏è  CONFIGURA√á√ÉO ATUAL")
        print("="*50)
        
        important_configs = [
            ("LOCAL_MODEL_PATH", config.LOCAL_MODEL_PATH),
            ("RHO_SPACE_DIMENSION", config.RHO_SPACE_DIMENSION),
            ("ENABLE_REFINEMENT_CYCLE", config.ENABLE_REFINEMENT_CYCLE),
            ("MAX_REFINEMENT_ATTEMPTS", config.MAX_REFINEMENT_ATTEMPTS),
            ("DEVICE", config.DEVICE),
            ("N_GPU_LAYERS", config.N_GPU_LAYERS),
        ]
        
        for name, value in important_configs:
            print(f"{name}: {value}")
        
        print("="*50)

    def print_help(self):
        """Imprime ajuda do sistema"""
        
        print("\n" + "="*50)
        print("‚ùì COMANDOS DISPON√çVEIS")
        print("="*50)
        print("status  - Mostra estat√≠sticas do sistema")
        print("reset   - Reseta sistema para estado inicial")  
        print("debug   - Alterna modo debug on/off")
        print("model   - Mostra informa√ß√µes do modelo")
        print("config  - Mostra configura√ß√£o atual")
        print("help    - Mostra esta ajuda")
        print("sair    - Encerra o sistema")
        print("="*50)

    def run(self):
        """Loop principal do sistema"""
        
        if not self.model_handler or not self.kernel:
            print("‚ùå Sistema n√£o inicializado corretamente. Encerrando.")
            return
        
        try:
            while True:
                print(f"\n{'='*30}")
                user_input = input("üë§ Voc√™: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == 'sair':
                    break
                
                # Verifica comandos especiais
                if self.handle_special_commands(user_input):
                    continue
                
                # Executa ciclo de intera√ß√£o normal
                try:
                    result = self.run_interaction_cycle(user_input)
                    
                    # Exibe resposta
                    print(f"\nü§ñ IA: {result['response']}")
                    
                    # Exibe metadados se debug ativo
                    if config.ENABLE_DEBUG_LOGGING:
                        print(f"\nüìà Tentativas: {result['attempts']}")
                        health = result['diagnostics'].get('overall_health', 0)
                        print(f"üíö Sa√∫de: {health:.3f}")
                    
                except KeyboardInterrupt:
                    print("\n‚è∏Ô∏è  Intera√ß√£o interrompida pelo usu√°rio")
                    continue
                except Exception as e:
                    print(f"\n‚ùå Erro na intera√ß√£o: {e}")
                    if config.ENABLE_DEBUG_LOGGING:
                        traceback.print_exc()
                    continue
        
        except KeyboardInterrupt:
            print("\n\n‚è∏Ô∏è  Sistema interrompido pelo usu√°rio")
        
        finally:
            self.print_session_summary()

    def print_session_summary(self):
        """Imprime resumo da sess√£o"""
        
        print("\n" + "="*60)
        print("üìã RESUMO DA SESS√ÉO")
        print("="*60)
        
        print(f"Total de intera√ß√µes: {self.session_stats['interactions']}")
        print(f"Refinamentos disparados: {self.session_stats['refinements_triggered']}")
        
        if self.session_stats['interactions'] > 0:
            refinement_rate = (self.session_stats['refinements_triggered'] / 
                             self.session_stats['interactions']) * 100
            print(f"Taxa de refinamento: {refinement_rate:.1f}%")
            print(f"Sa√∫de m√©dia: {self.session_stats['avg_health_score']:.3f}")
        
        if self.session_stats['dominant_pathologies']:
            print("\nPatologias mais frequentes:")
            sorted_pathologies = sorted(self.session_stats['dominant_pathologies'].items(),
                                      key=lambda x: x[1], reverse=True)
            for pathology, count in sorted_pathologies:
                print(f"  - {pathology}: {count}x")
        
        print("\nüéØ SISTEMA ONTOL√ìGICO ENCERRADO")
        print("="*60)


# *** ADICIONE ESTA FUN√á√ÉO DE GERA√á√ÉO COM TIMEOUT ***
def generate_with_timeout(self, current_prompt, timeout_seconds=30):
    """Gera resposta com timeout para evitar travamentos"""
    
    import signal
    import threading
    
    result = {"success": False, "output": None, "error": None}
    
    def timeout_handler(signum, frame):
        raise TimeoutError("Gera√ß√£o excedeu tempo limite")
    
    def generate_thread():
        try:
            output = self.model_handler.generate_response(
                current_prompt, **self.regulation_params
            )
            result["output"] = output
            result["success"] = True
        except Exception as e:
            result["error"] = str(e)
    
    try:
        # Configura timeout
        if hasattr(signal, 'SIGALRM'):  # Unix/Linux/Mac
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(timeout_seconds)
        
        # Executa gera√ß√£o
        thread = threading.Thread(target=generate_thread)
        thread.daemon = True
        thread.start()
        thread.join(timeout_seconds)
        
        if thread.is_alive():
            print(f"‚è∞ Timeout ap√≥s {timeout_seconds}s - for√ßando parada")
            return {
                "text": "‚è∞ Gera√ß√£o interrompida por timeout. Ajustando par√¢metros...",
                "logits": np.array([]),
                "tokens": [],
                "generation_stats": {"timeout": True},
                "internal_states": {"timeout": True}
            }
        
        if hasattr(signal, 'SIGALRM'):
            signal.alarm(0)  # Cancela timeout
        
        if result["success"]:
            return result["output"]
        else:
            raise Exception(result["error"] or "Erro desconhecido na gera√ß√£o")
            
    except TimeoutError:
        print(f"‚è∞ Timeout na gera√ß√£o ap√≥s {timeout_seconds}s")
        return {
            "text": "‚è∞ Timeout na gera√ß√£o. Par√¢metros muito restritivos.",
            "logits": np.array([]),
            "tokens": [],
            "generation_stats": {"timeout": True},
            "internal_states": {"timeout": True}
        }
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o com timeout: {e}")
        return {
            "text": f"‚ùå Erro na gera√ß√£o: {str(e)[:100]}",
            "logits": np.array([]),
            "tokens": [],
            "generation_stats": {"error": str(e)},
            "internal_states": {"error": str(e)}
        }


def main():
    """Fun√ß√£o principal"""
    
    try:
        # Cria e executa o sistema
        system = OntologicalSystem()
        system.run()
        
    except Exception as e:
        print(f"\n‚ùå ERRO CR√çTICO NO SISTEMA: {e}")
        traceback.print_exc()
        print("\nüí° Dicas para resolu√ß√£o:")
        print("   1. Verifique se config.py est√° correto")
        print("   2. Verifique se o modelo GGUF existe no caminho especificado")
        print("   3. Verifique se as depend√™ncias est√£o instaladas")
        print("   4. Execute com 'debug' para mais informa√ß√µes")
        
        sys.exit(1)


if __name__ == '__main__':
    main()